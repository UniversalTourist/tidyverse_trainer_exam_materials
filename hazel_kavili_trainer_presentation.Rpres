Week 1: Intro to Data Wrangling with dplyr
========================================================
author: Hazel KAVILI
date: "`r Sys.Date()`"
autosize: true

Install Libraries
========================================================
We'll load the packages with `library(tidyverse)` instead of loading the core packages. Today we'll focus on `dplyr` (and one function from `readr` package for one-time).

```{r}
#install.packages("tidyverse")
library(tidyverse)
```

Load Data Into R
========================================================
We'll use a data set about coffee ratings from weekly [Tidy Tuesday challenge ](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-07-07/readme.md). 

```{r, warning=FALSE, message=FALSE, echo=TRUE}
coffee_ratings <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-07/coffee_ratings.csv')
```

First Glimpse to Data 
========================================================
Let's take a look at the data set with `glimpse` function.

```{r, warning=FALSE, message=FALSE}
glimpse(coffee_ratings)
```

Summary of Data 
========================================================
There are some other functions to check your data: `str`, `summary`, `glimpse` , `head`, `tail`

```{r, warning=FALSE, message=FALSE}
head(coffee_ratings, n = 3)
```


Comparison with base R and Tidyverse
========================================================
```{r, warning=FALSE, message=FALSE, eval = FALSE}

coffee_ratings[ , c('species', 'country_of_origin')]

```

```{r warning=FALSE, message=FALSE, eval = FALSE}
coffee_ratings %>% 
  select(species, country_of_origin)

```


========================================================
## Did you see *Pipes*? *( %>% )*

```{r, eval = FALSE, warning=FALSE, message=FALSE, echo = TRUE}
coffee_ratings %>%
  group_by(species) %>%
  summarise(avg_rating = mean(total_cup_points),
            proportion = n()/nrow(coffee_ratings))
```



========================================================
## *Select:* Choosing is not losing!

```{r, warning=FALSE, message=FALSE}
coffee_ratings %>% 
  select(species, country_of_origin, color, certification_body) %>% 
  head()
```


========================================================
## *Select:* we can use the column index to choose variables

```{r, warning=FALSE, message=FALSE}
coffee_ratings %>% 
  select(1:4, 21:34) %>% 
  head()
```

========================================================
## *Filter:* Do we want everything?

```{r, warning=FALSE, message=FALSE}
coffee_ratings %>% 
  filter(country_of_origin == "Ethiopia") %>% 
  head(n = 3)
```

How should we fill the blank areas?
========================================================
We need to *select* total_cup_points, species, owner, countyr_of_origin and number_of_bags. Then *filter* country of origin for only Brazil and total cup points is higher than 70, then look at the *first 3 rows* of data set.

```{r, eval=FALSE, echo = TRUE}

coffee_ratings data %>% 
  ____(_:_, number_of_bags) %>% 
  ____(____ == "Brazil") %>%
  ____(total_cup_points > ___) %>% 
  head(n = __)
  

```

Here is the solution:
========================================================

```{r, eval=TRUE, echo = TRUE}
coffee_ratings %>% 
  select(1:4, number_of_bags) %>% 
  filter(country_of_origin == "Brazil") %>%
  filter(total_cup_points > 70) %>% 
  head(n = 3)
```

========================================================
## *Arrange:*  Let's order the rows
```{r}
coffee_ratings %>% 
  select(species, country_of_origin, color, sweetness) %>% 
  arrange(sweetness) %>% 
  head()
```

```{r}
coffee_ratings %>% 
  select(species, country_of_origin, color, sweetness) %>% 
  arrange(desc(sweetness)) %>% 
  head()
```


========================================================
## *Group_by & Summarise:* Let's create associations among groups!
Group by help us to find ...
We can use functions like `mean`, `median`, `sum`, `sd`, `max`, `min` to find out some group statistics.

```{r, eval=TRUE, echo = TRUE}
coffee_ratings %>%
  group_by(species) %>%
  summarise(avg_rating = mean(total_cup_points),
            proportion = n()/nrow(coffee_ratings))
```

========================================================
## *Group_by & Summarise:* Let's create associations among groups!

```{r, eval=TRUE, echo = TRUE}
coffee_ratings %>%
  group_by(country_of_origin) %>%
  summarise(avg_rating = mean(total_cup_points),
            median_rating = median(total_cup_points)
            )
```


========================================================
## *Mutate:* We need a new column!
Mutate helps us to create a new column by using othe
```{r, eval=FALSE, echo = TRUE}
coffee_ratings %>% 
  select(species, country_of_origin, processing_method) %>% 
  mutate(is_processing_method_full = ifelse(!is.na(processing_method), 1, 0))
    
```



Let's put it all together!
========================================================
Can we find the true order of that code piece?

```{r, eval = FALSE, echo = TRUE}
1- filter(species == "Arabica")  
2- filter(!is.na(country_of_origin)) 
3- select(total_cup_points, species, country_of_origin, processing_method, aroma, flavor, aftertaste)
4- coffee_ratings
5- arrange(mean_aroma) 
6- summarise(mean_aroma = mean(aroma),
            mean_flavor = mean(flavor),
            mean_aftertaste = mean(aftertaste))
7- group_by(country_of_origin)

```

Here is the solution:
========================================================

```{r}
coffee_ratings %>% 
  select(total_cup_points, species, country_of_origin, processing_method, aroma, flavor, aftertaste) %>%
  filter(species == "Arabica") %>% 
  filter(!is.na(country_of_origin)) %>% 
  group_by(country_of_origin) %>% 
  summarise(mean_aroma = mean(aroma),
            mean_flavor = mean(flavor),
            mean_aftertaste = mean(aftertaste)) %>%
  arrange(mean_aroma) 

```


Good job!
========================================================
Thank you for joining the training! 

You can find the all lesson materials my [Github page.](https://github.com/UniversalTourist/tidyverse_trainer_exam_materials)

Any questions? I'd be happy to answer! 

















