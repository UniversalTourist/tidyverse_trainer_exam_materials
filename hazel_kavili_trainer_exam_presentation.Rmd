---
title: "Week 1: Intro to dplyr"
author: "Hazel KAVILI"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Install Libraries
We'll load the packages with `library(tidyverse)` instead of loading the core packages one by one. 
Today we'll focus on `dplyr` (and one function from `readr` package for one-time).

```{r, warning=FALSE, message=FALSE, echo=TRUE}
library(tidyverse)
```

## Load Data Into R
Next wthing we'll do is load the data into our R environment. We'll use a data set about coffee ratings from weekly [Tidy Tuesday challenge ](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-07-07/readme.md). 

We'll use `read_csv` function from readr package to get the data, and assign it to `coffee_ratings`. In the rest of the document, we'll use that name to call our data frame.

```{r, warning=FALSE, message=FALSE, echo=TRUE}
coffee_ratings <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-07/coffee_ratings.csv')
```

## Summary of data
Let's look at our data frame to get to know it.
There are some functions to check the structure and summary of the data: `str`, `summary`, `glimpse` are the most common ones.

```{r, warning=FALSE, message=FALSE, eval=FALSE}
glimpse(coffee_ratings)
```


```{r, warning=FALSE, message=FALSE}
head(coffee_ratings, n = 3)
```

There are 43 variables (columns) and 1339 rows in our data frame. There is data for both Arabica and Robusta beans, across many countries and professionally rated on a 0-100 scale. All sorts of scoring/ratings for things like acidity, sweetness, fragrance, balance, etc - may be useful for either separating into visualizations/categories or for modeling/recommenders.

## Comparison with base R and Tidyverse
Before moving into dplyr verbs, I'd like to show you a comparison of base R and tidyverse. 
The two code chunks are doing the same thing: selecting two columns from our dataframe. Can you tell which one is more intuitive? 

```{r, warning=FALSE, message=FALSE, eval=FALSE}
coffee_ratings[ , c('species', 'country_of_origin')]
```

```{r, warning=FALSE, message=FALSE, eval=FALSE}
coffee_ratings %>% 
  select(species, country_of_origin)
```


## Did you see *Pipes*? *( %>% )*
Did you see that ( %>% ) sign in the previous code piece? 
It is called Pipe and it helps us to connect our dplyr verbs. We'll use it a lot during our session! 
Let's try to read our code below: I have the dataframe called coffee_ratings, I call it. And then I group that dataframe by `species` variable and then I summarise it with two statistics. One is mean of a variable and the other is some proportion. 

What I see in here is that everything is chained, right? I can read that code from left to right like a sentence. Pipe helps us to connect those verbs.

```{r, eval = FALSE, warning=FALSE, message=FALSE, echo = TRUE }
coffee_ratings %>%
  group_by(species) %>%
  summarise(avg_rating = mean(total_cup_points),
            proportion = n()/nrow(coffee_ratings))
```

## *Select:* Choosing is not losing!
Now we are moving to our first verb. `select` helps us select the variables we want to use or we need for our analysis. We probably don't need all 43 variables to answer some questions.

```{r, warning=FALSE, message=FALSE}
coffee_ratings %>% 
  select(species, country_of_origin, color, certification_body) %>% 
  head()
```

```{r, warning=FALSE, message=FALSE}
  select(coffee_ratings, 1:4, 21:34) %>% 
  head()
```

Most of the dplyr verbs have that structure:
```{r, eval=FALSE, echo=TRUE}
1- dplyr_verb(data_frame, colum_name, some_other_arguments)
2- data_frame %>% dplyr_verb(column_name, some_other_arguments)
```


## *Filter:* Do we want everything?
Let's say we want to look at our coffee_ratings dataset only for Ethiopia originated coffees. Then what we need to do is `filter` our dataset by using necessary column and value:

```{r, warning=FALSE, message=FALSE}
coffee_ratings %>% 
  filter(country_of_origin == "Ethiopia") %>% 
  head(n = 3)
```

## How should we fill the blank areas?
Now it's time for a quick question. 
We need to *select* total_cup_points, species, owner, countyr_of_origin and number_of_bags. Then *filter* country of origin for only Brazil and total cup points is higher than 70, then look at the *first 3 rows* of data set.

```{r, eval=FALSE, echo = TRUE}

coffee_ratings data %>% 
  ____(_:_, number_of_bags) %>% 
  ____(____ == "Brazil") %>%
  ____(total_cup_points > ___) %>% 
  head(n = __)
  

```

## Here is the solution:
```{r, eval=TRUE, echo = TRUE}
coffee_ratings %>% 
  select(1:4, number_of_bags) %>% 
  filter(country_of_origin == "Brazil") %>%
  filter(total_cup_points > 70) %>% 
  head(n = 3)
```

## *Arrange:*  Let's bring some order to data!
`arrange` sorts a data frame by one or more columns. Let's say we want to look at our data frame arranged by `sweetness`. In default, your dataset will be arranged bu ascending order.

```{r}
coffee_ratings %>% 
  arrange(sweetness) %>% 
  head()
```

If we want to order it by descending order of sweetness, we can use this syntax.
```{r}
coffee_ratings %>% 
  select(total_cup_points, species, country_of_origin, color, sweetness) %>% 
  arrange(desc(sweetness)) %>% 
  head()
```

## *Group_by & Summarise:* Let's create associations among groups!

We often want to look at our data by some group (if we have) for example country, year, age, gender, education, etc. to spot some differences (if there is).
`group_by` gives the data frame a grouping using one or more columns, which modifies the subsequent call to `summarize`. 

We can use functions like `mean`, `median`, `sum`, `sd`, `max`, `min` to find out some group statistics inside of `summarize` function.

```{r, eval=TRUE, echo = TRUE}
coffee_ratings %>%
  group_by(species) %>%
  summarise(avg_rating = mean(total_cup_points),
            proportion = n()/nrow(coffee_ratings))
```


```{r, eval=TRUE, echo = TRUE}
coffee_ratings %>%
  group_by(country_of_origin) %>%
  summarise(avg_rating = mean(total_cup_points),
            median_rating = median(total_cup_points)
            )
```

## *Mutate:* We need a new column!

`mutate` lets us add or overwrite columns by computing a new value for them.
For example, in the code below, we want a column name `is_processing_method_full` which is filled by checking if `processing_method` have some value or not. If it is not NA, we'll write 1, otherwise 0. 

We didn't have `is_processing_method_full` before but we create it by using `processing_method` variable.

```{r, eval=FALSE, echo = TRUE}
coffee_ratings %>% 
  select(species, country_of_origin, processing_method) %>% 
  mutate(is_processing_method_full = ifelse(!is.na(processing_method), 1, 0))
    
```


## Let's put it all together!
We want to look at the mean of aroma, flavor and aftertast variables by countries.
Can we find the true order of that code piece?

```{r, eval = FALSE, echo = TRUE}
1- filter(species == "Arabica")  
2- filter(!is.na(country_of_origin)) 
3- select(total_cup_points, species, country_of_origin, processing_method, aroma, flavor, aftertaste)
4- coffee_ratings
5- arrange(mean_aroma) 
6- summarise(mean_aroma = mean(aroma),
            mean_flavor = mean(flavor),
            mean_aftertaste = mean(aftertaste))
7- group_by(country_of_origin)

```


## Here is the solution:
```{r}
coffee_ratings %>% 
  select(total_cup_points, species, country_of_origin, processing_method, aroma, flavor, aftertaste) %>%
  filter(species == "Arabica") %>% 
  filter(!is.na(country_of_origin)) %>% 
  group_by(country_of_origin) %>% 
  summarise(mean_aroma = mean(aroma),
            mean_flavor = mean(flavor),
            mean_aftertaste = mean(aftertaste)) %>%
  arrange(mean_aroma) 
```


## Good job!
Thank you for joining the training! 

You can find the all lesson materials my [Github page.](https://github.com/UniversalTourist/tidyverse_trainer_exam_materials)

Any questions? I'd be happy to answer! 




